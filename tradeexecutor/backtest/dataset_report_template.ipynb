{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#\n",
    "# All code cells are hidden in the output by default\n",
    "#\n",
    "\n",
    "# Parameter cell. Will be replaced by export_backtest_report()\n",
    "parameters = {}\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T10:44:37.137791Z",
     "start_time": "2025-03-11T10:44:37.134705Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "#\n",
    "# Setting up\n",
    "#\n",
    "\n",
    "from tradeexecutor.utils.notebook import setup_charting_and_output, OutputMode, set_notebook_logging\n",
    "\n",
    "import traceback \n",
    "import pickle\n",
    "\n",
    "saved_dataset = pickle.load(open(parameters[\"dataset_file\"], \"rb\"))\n",
    "strategy_universe = pickle.load(open(parameters[\"universe_file\"], \"rb\"))\n",
    "\n",
    "\n",
    "setup_charting_and_output(OutputMode.static, image_format=\"png\", width=1500, height=1000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-11T10:44:37.161939Z",
     "start_time": "2025-03-11T10:44:37.148308Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dataset_file'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Setting up\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpickle\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m saved_dataset \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(\u001B[43mparameters\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdataset_file\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m      8\u001B[0m strategy_universe \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniverse_file\u001B[39m\u001B[38;5;124m\"\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[0;31mKeyError\u001B[0m: 'dataset_file'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#\n",
    "# Parameters\n",
    "#\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from tradeexecutor.strategy.parameters import StrategyParameters\n",
    "import datetime\n",
    "from tradeexecutor.strategy.default_routing_options import TradeRouting\n",
    "from tradeexecutor.strategy.cycle import CycleDuration\n",
    "from tradingstrategy.timebucket import TimeBucket\n",
    "\n",
    "\n",
    "class Parameters:\n",
    "    id = \"equally-weighted-index\"\n",
    "    \n",
    "    if saved_dataset.set.time_bucket >= TimeBucket.d1:\n",
    "        # For longer timeframesd cycle and time bucket are always the same\n",
    "        candle_time_bucket = saved_dataset.set.time_bucket\n",
    "        cycle_duration = CycleDuration.from_timebucket(saved_dataset.set.time_bucket)\n",
    "    else:\n",
    "        # Handle hourly with higher cycles as otherwise too slow\n",
    "        candle_time_bucket = saved_dataset.set.time_bucket\n",
    "        cycle_duration = CycleDuration.cycle_1d\n",
    "\n",
    "    # Coingecko categories to include\n",
    "    # s\n",
    "    # See list here: TODO\n",
    "    #\n",
    "    chain_id = saved_dataset.set.chain\n",
    "    exchanges = saved_dataset.set.exchanges\n",
    "\n",
    "    #\n",
    "    # Basket construction and rebalance parameters\n",
    "    #\n",
    "    min_asset_universe = 1  # How many assets we need in the asset universe to start running the index\n",
    "    max_assets_in_portfolio = 99  # How many assets our basket can hold once\n",
    "    allocation = 0.98  # Allocate all cash to volatile pairs\n",
    "    # min_rebalance_trade_threshold_pct = 0.05  # % of portfolio composition must change before triggering rebalacne\n",
    "    individual_rebalance_min_threshold_usd = 75.0  # Don't make buys less than this amount\n",
    "    sell_rebalance_min_threshold = 5.00\n",
    "    per_position_cap_of_pool = 0.01  # Never own more than % of the lit liquidity of the trading pool\n",
    "    max_concentration = 0.20  # How large % can one asset be in a portfolio once\n",
    "    min_portfolio_weight = 0.0010  # Close position / do not open if weight is less than 10 BPS\n",
    "\n",
    "    # For the length of trailing sharpe used in inclusion criteria\n",
    "    rolling_volume_bars = pd.Timedelta(\"7d\") // candle_time_bucket.to_timedelta()\n",
    "    rolling_volatility_bars = pd.Timedelta(\"7d\") // candle_time_bucket.to_timedelta()\n",
    "    tvl_ewm_span = 7 * 24  # Smooth TVL inclusin criteria\n",
    "    min_volume = saved_dataset.set.min_weekly_volume  # USD\n",
    "    min_tvl = saved_dataset.set.min_tvl\n",
    "    min_token_sniffer_score = 20  # 20 = AAVE\n",
    "\n",
    "    #\n",
    "    #\n",
    "    # Backtesting only\n",
    "    # Limiting factor: Aave v3 on Base starts at the end of DEC 2023\n",
    "    #\n",
    "    backtest_start = saved_dataset.set.start\n",
    "    backtest_end = saved_dataset.set.end\n",
    "    initial_cash = 100_000\n",
    "    out_of_money_threshold = 1_000  # If our capital falls below this limit, give up\n",
    "\n",
    "    #\n",
    "    # Live only\n",
    "    #\n",
    "    routing = TradeRouting.default\n",
    "    # required_history_period = datetime.timedelta(days=2 * 14 + 1)\n",
    "    slippage_tolerance = 0.0060  # 0.6%\n",
    "\n",
    "parameters = StrategyParameters.from_class(Parameters)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset information\n",
    "\n",
    "Information about the prepared backtest dataset."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = saved_dataset.get_info()\n",
    "display(df)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Equally-weighed index backtest parameters\n",
    "\n",
    "These parameters present the trading strategy parameters to generate equally-weighted index for this dataset."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tradeexecutor.strategy.parameters import display_parameters\n",
    "display_parameters(parameters)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Prepare benchmark\n",
    "\n",
    "- Run a backtest for equally weighted index strategy\n",
    "- Used to display "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tradingstrategy.utils.forward_fill import forward_fill\n",
    "from tradeexecutor.strategy.execution_context import ExecutionContext\n",
    "from tradeexecutor.state.identifier import TradingPairIdentifier\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import IndicatorSource\n",
    "from tradeexecutor.strategy.trading_strategy_universe import TradingStrategyUniverse\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import calculate_and_load_indicators_inline\n",
    "from tradeexecutor.strategy.pandas_trader.indicator import IndicatorDependencyResolver\n",
    "from tradeexecutor.state.types import USDollarAmount\n",
    "from tradeexecutor.strategy.pandas_trader.indicator_decorator import IndicatorRegistry\n",
    "\n",
    "indicators = IndicatorRegistry()\n",
    "\n",
    "empty_series = pd.Series([], index=pd.DatetimeIndex([]))\n",
    "\n",
    "@indicators.define()\n",
    "def volatility(close: pd.Series, rolling_volatility_bars: int) -> pd.Series:\n",
    "    \"\"\"Calculate the rolling volatility for rebalancing the index for each decision cycle.\"\"\"\n",
    "    price_diff = close.pct_change()\n",
    "    rolling_std = price_diff.rolling(window=rolling_volatility_bars).std()\n",
    "    return rolling_std\n",
    "\n",
    "\n",
    "@indicators.define()\n",
    "def rolling_cumulative_volume(volume: pd.Series, rolling_volume_bars: int) -> pd.Series:\n",
    "    \"\"\"Calculate rolling volume of the pair.\n",
    "\n",
    "    - Used in inclusion criteria\n",
    "    \"\"\"\n",
    "    rolling_volume = volume.rolling(window=rolling_volume_bars).sum()\n",
    "    return rolling_volume\n",
    "\n",
    "\n",
    "@indicators.define()\n",
    "def rolling_liquidity_avg(close: pd.Series, rolling_volume_bars: int) -> pd.Series:\n",
    "    \"\"\"Calculate rolling liquidity average\n",
    "\n",
    "    - This is either TVL or XY liquidity (one sided) depending on the trading pair DEX type\n",
    "\n",
    "    - Used in inclusion criteria\n",
    "    \"\"\"\n",
    "    rolling_liquidity_close = close.rolling(window=rolling_volume_bars).mean()\n",
    "    return rolling_liquidity_close\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(rolling_cumulative_volume,), source=IndicatorSource.strategy_universe)\n",
    "def volume_inclusion_criteria(\n",
    "        strategy_universe: TradingStrategyUniverse,\n",
    "        min_volume: USDollarAmount,\n",
    "        rolling_volume_bars: int,\n",
    "        dependency_resolver: IndicatorDependencyResolver,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate pair volume inclusion criteria.\n",
    "\n",
    "    - Avoid including illiquid / broken pairs in the set: Pair is included when it has enough volume\n",
    "\n",
    "    TODO: Add liquidity check later\n",
    "\n",
    "    :return:\n",
    "        Series where each timestamp is a list of pair ids meeting the criteria at that timestamp\n",
    "    \"\"\"\n",
    "\n",
    "    series = dependency_resolver.get_indicator_data_pairs_combined(\n",
    "        rolling_cumulative_volume,\n",
    "        parameters={\"rolling_volume_bars\": rolling_volume_bars},\n",
    "    )\n",
    "\n",
    "    # Get mask for days when the rolling volume meets out criteria\n",
    "    mask = series >= min_volume\n",
    "    mask_true_values_only = mask[mask == True]\n",
    "\n",
    "    # Turn to a series of lists\n",
    "    series = mask_true_values_only.groupby(level='timestamp').apply(lambda x: x.index.get_level_values('pair_id').tolist())\n",
    "    return series\n",
    "\n",
    "\n",
    "@indicators.define(source=IndicatorSource.tvl)\n",
    "def tvl(\n",
    "    close: pd.Series,\n",
    "    execution_context: ExecutionContext,\n",
    "    timestamp: datetime.datetime,\n",
    "    candle_time_bucket: TimeBucket,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Get TVL series for a pair.\n",
    "\n",
    "    - Because TVL data is 1d and we use 1h everywhere else, we need to forward fill\n",
    "\n",
    "    - Use previous hourly close as the value\n",
    "    \"\"\"\n",
    "    if execution_context.live_trading:\n",
    "        # TVL is daily data.\n",
    "        # We need to forward fill until the current hour.\n",
    "        # Use our special ff function.\n",
    "        assert isinstance(timestamp, pd.Timestamp), f\"Live trading needs forward-fill end time, we got {timestamp}\"\n",
    "        df = pd.DataFrame({\"close\": close})\n",
    "        df_ff = forward_fill(\n",
    "            df,\n",
    "            Parameters.candle_time_bucket.to_frequency(),\n",
    "            columns=(\"close\",),\n",
    "            forward_fill_until=pd.Timestamp(timestamp),\n",
    "        )\n",
    "        series = df_ff[\"close\"]\n",
    "        return series\n",
    "    else:        \n",
    "        return close.resample(candle_time_bucket.to_frequency()).ffill()\n",
    "        # return close\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(tvl,), source=IndicatorSource.dependencies_only_per_pair)\n",
    "def tvl_ewm(\n",
    "    pair: TradingPairIdentifier,\n",
    "    tvl_ewm_span: float,\n",
    "    dependency_resolver: IndicatorDependencyResolver,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Get smoothed TVL series for a pair.\n",
    "\n",
    "    - Interpretation: If you set span=5, for example, the ewm function will compute an exponential moving average where the weight of the most recent observation is about 33.3% (since α=2/(5+1)≈0.333) and this weight decreases exponentially for older observations.\n",
    "\n",
    "    - We forward fill gaps, so there is no missing data in decide_trades()\n",
    "\n",
    "    - Currently unused in the strategy itself\n",
    "    \"\"\"\n",
    "    tvl_ff = dependency_resolver.get_indicator_data(\n",
    "        tvl,\n",
    "        pair=pair,\n",
    "    )\n",
    "    return tvl_ff.ewm(span=tvl_ewm_span).mean()\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(tvl_ewm, tvl), source=IndicatorSource.dependencies_only_universe)\n",
    "def tvl_inclusion_criteria(\n",
    "        min_tvl: USDollarAmount,\n",
    "        dependency_resolver: IndicatorDependencyResolver,\n",
    ") -> pd.Series:\n",
    "    \"\"\"The pair must have min XX,XXX USD one-sided TVL to be included.\n",
    "\n",
    "    - If the Uniswap pool does not have enough ETH or USDC deposited, skip the pair as a scam\n",
    "\n",
    "    :return:\n",
    "        Series where each timestamp is a list of pair ids meeting the criteria at that timestamp\n",
    "    \"\"\"\n",
    "\n",
    "    series = dependency_resolver.get_indicator_data_pairs_combined(tvl)\n",
    "    mask = series >= min_tvl\n",
    "    # Turn to a series of lists\n",
    "    mask_true_values_only = mask[mask == True]\n",
    "    series = mask_true_values_only.groupby(level='timestamp').apply(lambda x: x.index.get_level_values('pair_id').tolist())\n",
    "    return series\n",
    "\n",
    "\n",
    "@indicators.define(\n",
    "    source=IndicatorSource.strategy_universe\n",
    ")\n",
    "def trading_availability_criteria(\n",
    "        strategy_universe: TradingStrategyUniverse,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Is pair tradeable at each hour.\n",
    "\n",
    "    - The pair has a price candle at that\n",
    "    - Mitigates very corner case issues that TVL/liquidity data is per-day whileas price data is natively per 1h\n",
    "      and the strategy inclusion criteria may include pair too early hour based on TVL only,\n",
    "      leading to a failed attempt to rebalance in a backtest\n",
    "    - Only relevant for backtesting issues if we make an unlucky trade on the starting date\n",
    "      of trading pair listing\n",
    "\n",
    "    :return:\n",
    "        Series with with index (timestamp) and values (list of pair ids trading at that hour)\n",
    "    \"\"\"\n",
    "    # Trading pair availability is defined if there is a open candle in the index for it.\n",
    "    # Because candle data is forward filled, we should not have any gaps in the index.\n",
    "    candle_series = strategy_universe.data_universe.candles.df[\"open\"]\n",
    "    pairs_per_timestamp = candle_series.groupby(level='timestamp').apply(lambda x: x.index.get_level_values('pair_id').tolist())\n",
    "    return pairs_per_timestamp\n",
    "\n",
    "\n",
    "@indicators.define(\n",
    "    dependencies=[\n",
    "        volume_inclusion_criteria,\n",
    "        tvl_inclusion_criteria,\n",
    "        trading_availability_criteria\n",
    "    ],\n",
    "    source=IndicatorSource.strategy_universe\n",
    ")\n",
    "def inclusion_criteria(\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    "    min_volume: USDollarAmount,\n",
    "    rolling_volume_bars: int,\n",
    "    min_tvl: USDollarAmount,\n",
    "    dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    \"\"\"Pairs meeting all of our inclusion criteria.\n",
    "\n",
    "    - Give the tradeable pair set for each timestamp\n",
    "\n",
    "    :return:\n",
    "        Series where index is timestamp and each cell is a list of pair ids matching our inclusion criteria at that moment\n",
    "    \"\"\"\n",
    "\n",
    "    volume_series = dependency_resolver.get_indicator_data(\n",
    "        volume_inclusion_criteria,\n",
    "        parameters={\n",
    "            \"min_volume\": min_volume,\n",
    "            \"rolling_volume_bars\": rolling_volume_bars,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    tvl_series = dependency_resolver.get_indicator_data(\n",
    "        tvl_inclusion_criteria,\n",
    "        parameters={\n",
    "            \"min_tvl\": min_tvl,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    trading_availability_series = dependency_resolver.get_indicator_data(trading_availability_criteria)\n",
    "\n",
    "    #\n",
    "    # Process all pair ids as a set and the final inclusion\n",
    "    # criteria is union of all sub-criterias\n",
    "    #\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"tvl_pair_ids\": tvl_series,\n",
    "        \"volume_pair_ids\": volume_series,\n",
    "        \"trading_availability_pair_ids\": trading_availability_series,\n",
    "    })\n",
    "\n",
    "    # https://stackoverflow.com/questions/33199193/how-to-fill-dataframe-nan-values-with-empty-list-in-pandas\n",
    "    df = df.fillna(\"\").apply(list)\n",
    "\n",
    "    def _combine_criteria(row):\n",
    "        final_set = set(row[\"volume_pair_ids\"]) & \\\n",
    "                    set(row[\"tvl_pair_ids\"]) & \\\n",
    "                    set(row[\"trading_availability_pair_ids\"])\n",
    "        return final_set\n",
    "\n",
    "    union_criteria = df.apply(_combine_criteria, axis=1)\n",
    "\n",
    "    # Inclusion criteria data can be spotty at the beginning when there is only 0 or 1 pairs trading,\n",
    "    # so we need to fill gaps to 0\n",
    "    full_index = pd.date_range(\n",
    "        start=union_criteria.index.min(),\n",
    "        end=union_criteria.index.max(),\n",
    "        freq=Parameters.candle_time_bucket.to_frequency(),\n",
    "    )\n",
    "    reindexed = union_criteria.reindex(full_index, fill_value=[])\n",
    "    return reindexed\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(volume_inclusion_criteria,), source=IndicatorSource.dependencies_only_universe)\n",
    "def volume_included_pair_count(\n",
    "        min_volume: USDollarAmount,\n",
    "        rolling_volume_bars: int,\n",
    "        dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    series = dependency_resolver.get_indicator_data(\n",
    "        volume_inclusion_criteria,\n",
    "        parameters={\"min_volume\": min_volume, \"rolling_volume_bars\": rolling_volume_bars},\n",
    "    )\n",
    "    return series.apply(len)\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(tvl_inclusion_criteria,), source=IndicatorSource.dependencies_only_universe)\n",
    "def tvl_included_pair_count(\n",
    "        min_tvl: USDollarAmount,\n",
    "        dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    \"\"\"Calculate number of pairs in meeting volatility criteria on each timestamp\"\"\"\n",
    "    series = dependency_resolver.get_indicator_data(\n",
    "        tvl_inclusion_criteria,\n",
    "        parameters={\"min_tvl\": min_tvl},\n",
    "    )\n",
    "    series = series.apply(len)\n",
    "\n",
    "    # TVL data can be spotty at the beginning when there is only 0 or 1 pairs trading,\n",
    "    # so we need to fill gaps to 0\n",
    "    full_index = pd.date_range(\n",
    "        start=series.index.min(),\n",
    "        end=series.index.max(),\n",
    "        freq=Parameters.candle_time_bucket.to_frequency(),\n",
    "    )\n",
    "    # Reindex and fill NaN with zeros\n",
    "    reindexed = series.reindex(full_index, fill_value=0)\n",
    "    return reindexed\n",
    "\n",
    "\n",
    "@indicators.define(dependencies=(inclusion_criteria,), source=IndicatorSource.dependencies_only_universe)\n",
    "def all_criteria_included_pair_count(\n",
    "        min_volume: USDollarAmount,\n",
    "        min_tvl: USDollarAmount,\n",
    "        rolling_volume_bars: int,\n",
    "        dependency_resolver: IndicatorDependencyResolver\n",
    ") -> pd.Series:\n",
    "    \"\"\"Series where each timestamp is the list of pairs meeting all inclusion criteria.\n",
    "\n",
    "    :return:\n",
    "        Series with pair count for each timestamp\n",
    "    \"\"\"\n",
    "    series = dependency_resolver.get_indicator_data(\n",
    "        \"inclusion_criteria\",\n",
    "        parameters={\n",
    "            \"min_volume\": min_volume,\n",
    "            \"min_tvl\": min_tvl,\n",
    "            \"rolling_volume_bars\": rolling_volume_bars,\n",
    "        },\n",
    "    )\n",
    "    return series.apply(len)\n",
    "\n",
    "\n",
    "@indicators.define(source=IndicatorSource.strategy_universe)\n",
    "def trading_pair_count(\n",
    "    strategy_universe: TradingStrategyUniverse,\n",
    ") -> pd.Series:\n",
    "    \"\"\"Get number of pairs that trade at each timestamp.\n",
    "\n",
    "    - Pair must have had at least one candle before the timestamp to be included\n",
    "\n",
    "    - Exclude benchmarks pairs we do not trade\n",
    "\n",
    "    :return:\n",
    "        Series with pair count for each timestamp\n",
    "    \"\"\"\n",
    "    \n",
    "    index = strategy_universe.data_universe.candles.df.index\n",
    "    assert isinstance(index, pd.MultiIndex), f\"Expected MultiIndex, got OHLCV candle index: {index}\"\n",
    "\n",
    "    # Get pair_id, timestamp -> timestamp, pair_id index    \n",
    "    series = strategy_universe.data_universe.candles.df[\"open\"]\n",
    "    swap_index = series.index.swaplevel(0, 1)\n",
    "\n",
    "    seen_pairs = set()\n",
    "    seen_data = {}\n",
    "\n",
    "    for timestamp, pair_id in swap_index:\n",
    "        seen_pairs.add(pair_id)\n",
    "        seen_data[timestamp] = len(seen_pairs)\n",
    "\n",
    "    series = pd.Series(seen_data.values(), index=list(seen_data.keys()))\n",
    "    return series\n",
    "\n",
    "\n",
    "# Calculate all indicators where parameters have changed and store the result on disk\n",
    "indicator_data = calculate_and_load_indicators_inline(\n",
    "    strategy_universe=strategy_universe,\n",
    "    create_indicators=indicators.create_indicators,\n",
    "    parameters=parameters,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tradeexecutor.strategy.alpha_model import AlphaModel\n",
    "from tradeexecutor.state.trade import TradeExecution\n",
    "from tradeexecutor.strategy.pandas_trader.strategy_input import StrategyInput\n",
    "from tradeexecutor.backtest.backtest_runner import run_backtest_inline\n",
    "from tradeexecutor.strategy.tvl_size_risk import USDTVLSizeRiskModel\n",
    "from tradeexecutor.strategy.weighting import weight_passthrouh, weight_equal\n",
    "\n",
    "\n",
    "def decide_trades(\n",
    "    input: StrategyInput\n",
    ") -> list[TradeExecution]:\n",
    "    \"\"\"For each strategy tick, generate the list of trades.\"\"\"\n",
    "    parameters = input.parameters\n",
    "    position_manager = input.get_position_manager()\n",
    "    state = input.state\n",
    "    timestamp = input.timestamp\n",
    "    indicators = input.indicators\n",
    "    strategy_universe = input.strategy_universe\n",
    "\n",
    "    # Build signals for each pair \n",
    "    alpha_model = AlphaModel(\n",
    "        timestamp,\n",
    "        close_position_weight_epsilon=parameters.min_portfolio_weight,  # 10 BPS is our min portfolio weight\n",
    "    )\n",
    "    \n",
    "    # Get pairs included in this rebalance cycle.\n",
    "    # This includes pair that have been pre-cleared in inclusion_criteria()\n",
    "    # with volume, volatility and TVL filters \n",
    "    included_pairs = indicators.get_indicator_value(\n",
    "        \"inclusion_criteria\",\n",
    "        na_conversion=False,\n",
    "    )\n",
    "    if included_pairs is None:\n",
    "        included_pairs = []\n",
    "    \n",
    "    # Do out of the money check\n",
    "    equity = state.portfolio.get_total_equity()\n",
    "    \n",
    "    if equity > parameters.out_of_money_threshold:\n",
    "        for pair_id in included_pairs:\n",
    "            pair = strategy_universe.get_pair_by_id(pair_id)\n",
    "            weight = 1\n",
    "            \n",
    "            alpha_model.set_signal(\n",
    "                pair,\n",
    "                weight,\n",
    "            )\n",
    "\n",
    "    # Calculate how much dollar value we want each individual position to be on this strategy cycle,\n",
    "    # based on our total available equity\n",
    "    portfolio = position_manager.get_current_portfolio()\n",
    "    \n",
    "    portfolio_target_value = portfolio.get_total_equity() * parameters.allocation\n",
    "\n",
    "    # Select max_assets_in_portfolio assets in which we are going to invest\n",
    "    # Calculate a weight for ecah asset in the portfolio using 1/N method based on the raw signal\n",
    "    alpha_model.select_top_signals(count=parameters.max_assets_in_portfolio)\n",
    "    alpha_model.assign_weights(method=weight_equal)\n",
    "    # alpha_model.assign_weights(method=weight_by_1_slash_n)\n",
    "\n",
    "    #\n",
    "    # Normalise weights and cap the positions\n",
    "    # \n",
    "    size_risk_model = USDTVLSizeRiskModel(\n",
    "        pricing_model=input.pricing_model,\n",
    "        per_position_cap=parameters.per_position_cap_of_pool,  # This is how much % by all pool TVL we can allocate for a position\n",
    "        missing_tvl_placeholder_usd=0,  # Placeholder for missing TVL data until we get the data off the chain\n",
    "    )\n",
    "\n",
    "    alpha_model.normalise_weights(\n",
    "        investable_equity=portfolio_target_value,\n",
    "        size_risk_model=size_risk_model,\n",
    "        max_weight=parameters.max_concentration,\n",
    "    )\n",
    "\n",
    "    # Load in old weight for each trading pair signal,\n",
    "    # so we can calculate the adjustment trade size\n",
    "    alpha_model.update_old_weights(\n",
    "        state.portfolio,\n",
    "        ignore_credit=True,\n",
    "    )\n",
    "    alpha_model.calculate_target_positions(position_manager)\n",
    "\n",
    "    # Shift portfolio from current positions to target positions\n",
    "    # determined by the alpha signals (momentum)\n",
    "    \n",
    "    # rebalance_threshold_usd = portfolio_target_value * parameters.min_rebalance_trade_threshold_pct\n",
    "    rebalance_threshold_usd = parameters.individual_rebalance_min_threshold_usd\n",
    "    \n",
    "    assert rebalance_threshold_usd > 0.1, \"Safety check tripped - something like wrong with strat code\"\n",
    "    trades = alpha_model.generate_rebalance_trades_and_triggers(\n",
    "        position_manager,\n",
    "        min_trade_threshold=rebalance_threshold_usd,  # Don't bother with trades under XXXX USD\n",
    "        invidiual_rebalance_min_threshold=parameters.individual_rebalance_min_threshold_usd,\n",
    "        execution_context=input.execution_context,\n",
    "        sell_rebalance_min_threshold=parameters.sell_rebalance_min_threshold,\n",
    "    )\n",
    "    return trades  # Return the list of trades we made in this cycle\n",
    "\n",
    "\n",
    "state = None\n",
    "try:\n",
    "    result = run_backtest_inline(\n",
    "        name=parameters.id,\n",
    "        engine_version=\"0.5\",\n",
    "        decide_trades=decide_trades,\n",
    "        create_indicators=indicators.create_indicators,\n",
    "        client=None,\n",
    "        universe=strategy_universe,\n",
    "        parameters=parameters,\n",
    "        # log_level=logging.INFO,\n",
    "        max_workers=1,\n",
    "        start_at=parameters.backtest_start,\n",
    "        end_at=parameters.backtest_end,\n",
    "    )\n",
    "    \n",
    "    state = result.state\n",
    "    \n",
    "    trade_count = len(list(state.portfolio.get_all_trades()))\n",
    "    print(f\"Backtesting completed, backtested strategy made {trade_count} trades\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to run backtest: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Asset universe\n",
    "\n",
    "- Show how the asset universe evolves over time\n",
    "- Respect the minimum TVL and volume criteria from dataset labelling "
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Inclusion criteria met (all)\": indicator_data.get_indicator_series(\"all_criteria_included_pair_count\"),\n",
    "    f\"Volume criteria {Parameters.min_volume:,} USD / {Parameters.rolling_volume_bars * Parameters.candle_time_bucket.to_pandas_timedelta() / datetime.timedelta(hours=24)} days met\": indicator_data.get_indicator_series(\"volume_included_pair_count\"),\n",
    "    f\"TVL criteria {Parameters.min_tvl:,} USD met\": indicator_data.get_indicator_series(\"tvl_included_pair_count\"),\n",
    "    \"Visible pairs\": indicator_data.get_indicator_series(\"trading_pair_count\"),\n",
    "})\n",
    "\n",
    "try:\n",
    "    fig = px.line(df, title='Trading pairs available for strategy to trade')\n",
    "    fig.update_yaxes(title=\"Number of assets\")\n",
    "    fig.update_xaxes(title=\"Time\")\n",
    "    fig.show()\n",
    "except Exception as e: \n",
    "    print(f\"Could not render asset universe chart: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Available trading pairs at the end of the period"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "display(df.tail(25))"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Equally-weighed index\n",
    "\n",
    "This is the [benchmark](https://tradingstrategy.ai/glossary/benchmark) of this trading universe.\n",
    "\n",
    "Here we compare display the results \n",
    "\n",
    "- Equally-weighted index of the trading universe\n",
    "- Some notable crypto assets in this trading universe \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.multi_asset_benchmark import get_benchmark_data\n",
    "from tradeexecutor.visual.benchmark import visualise_equity_curve_benchmark\n",
    "\n",
    "if state:\n",
    "    start_at = state.get_trading_time_range()[0]\n",
    "    \n",
    "    benchmark_indexes = get_benchmark_data(\n",
    "        strategy_universe,\n",
    "        cumulative_with_initial_cash=state.portfolio.get_initial_cash(),\n",
    "        start_at=start_at,\n",
    "    )\n",
    "    \n",
    "    fig = visualise_equity_curve_benchmark(\n",
    "        name=\"This strategy\",\n",
    "        title=\"Strategy vs. benchmark assets\",\n",
    "        state=state,\n",
    "        all_cash=state.portfolio.get_initial_cash(),\n",
    "        benchmark_indexes=benchmark_indexes,\n",
    "        height=800,\n",
    "        log_y=False,\n",
    "        start_at=start_at,\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Equity curve\n",
    "\n",
    "The equity curve allows to examine how stable the strategy profitability is.\n",
    "\n",
    "Here we plot\n",
    "\n",
    "- The strategy equity curve\n",
    "- Maximum drawdown\n",
    "- Daily profit"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tradeexecutor.analysis.multi_asset_benchmark import get_benchmark_data\n",
    "from tradeexecutor.visual.benchmark import visualise_equity_curve_benchmark\n",
    "\n",
    "if state:\n",
    "    benchmark_indexes = get_benchmark_data(\n",
    "        strategy_universe,\n",
    "        cumulative_with_initial_cash=state.portfolio.get_initial_cash(),\n",
    "        max_count=4,\n",
    "        # start_at=state.get_trading_time_range()[0],\n",
    "    )\n",
    "    \n",
    "    fig = visualise_equity_curve_benchmark(\n",
    "        state=state,    \n",
    "        benchmark_indexes=benchmark_indexes,\n",
    "        height=800,\n",
    "        log_y=True,\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No backtest results availabl4e\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Equity curve with drawdown\n",
    "\n",
    "- Showing drawndown as a separate chart"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tradeexecutor.visual.equity_curve import calculate_equity_curve, calculate_returns\n",
    "from tradeexecutor.visual.equity_curve import visualise_equity_curve\n",
    "\n",
    "if state:\n",
    "    curve = calculate_equity_curve(state)\n",
    "    returns = calculate_returns(curve)\n",
    "    fig = visualise_equity_curve(returns)\n",
    "    display(fig)\n",
    "else:\n",
    "    returns = None"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Market performance metrics\n",
    "\n",
    "Side-by-side comparison of equally-weighted index and some benchmark adjusts.\n",
    "\n",
    "See [risk-adjusted return](https://tradingstrategy.ai/glossary/risk-adjusted-return) to learn more about how to compare risk and reward ratios of different trading strategies.\n"
   ]
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tradeexecutor.analysis.multi_asset_benchmark import compare_strategy_backtest_to_multiple_assets\n",
    "\n",
    "if state is not None:\n",
    "    print(\"Metrics for the equally-weighted index\")\n",
    "    metrics = compare_strategy_backtest_to_multiple_assets(\n",
    "        state,\n",
    "        strategy_universe,\n",
    "        display=True,\n",
    "    )\n",
    "    display(metrics)\n",
    "else:\n",
    "    print(\"No backtest results available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Monthly returns\n",
    "\n",
    "Here we show the backtested returns by each month, and visualise the streaks of good and bad months.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tradeexecutor.visual.equity_curve import visualise_returns_over_time\n",
    "\n",
    "if returns is not None:\n",
    "    fig = visualise_returns_over_time(returns)\n",
    "    display(fig)\n",
    "else:\n",
    "    print(\"No backtest results availabl4e\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trading metrics\n",
    "\n",
    "Overview of the performance of trades this strategy took.\n",
    "\n",
    "- How many winning and losing trades we had\n",
    "- How much on average each trade made"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.trade_analyser import build_trade_analysis\n",
    "\n",
    "if state:\n",
    "    analysis = build_trade_analysis(state.portfolio)\n",
    "    \n",
    "    try:\n",
    "        summary_metrics = analysis.calculate_summary_statistics(state=state, time_bucket=strategy_universe.data_universe.time_bucket)\n",
    "        summary_metrics.display()\n",
    "    except Exception as e:\n",
    "        print(f\"Summary metrics information cannot be displayed. Exception: {e}\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"No backtest results availabl4e\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Periodic return distribution\n",
    "\n",
    "Show performance variations for different timeframes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tradeexecutor.visual.equity_curve import visualise_returns_distribution\n",
    "\n",
    "if returns is not None:\n",
    "    fig = visualise_returns_distribution(returns)\n",
    "    display(fig)\n",
    "else:\n",
    "    print(\"No backtest results available\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Asset weights\n",
    "\n",
    "- Show weights of different assets during the backtest period.\n",
    "- Equally weighted index considers liquidity of the trading pair (TVL)\n",
    "  and may not be able to deploy all capital"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tradeexecutor.analysis.weights import calculate_asset_weights, visualise_weights\n",
    "\n",
    "if state:\n",
    "    weights_series = calculate_asset_weights(state)\n",
    "    \n",
    "    fig = visualise_weights(\n",
    "        weights_series,\n",
    "        normalised=False,\n",
    "        include_reserves=True,\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig.show()\n",
    "else:\n",
    "    print(\"No backtest results availabl4e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trading pair breakdown\n",
    "\n",
    "Show gains and losses in individual trading pairs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tradeexecutor.analysis.multipair import analyse_multipair\n",
    "from tradeexecutor.analysis.multipair import format_multipair_summary\n",
    "\n",
    "if state and strategy_universe.get_pair_count() > 1:\n",
    "    multipair_summary = analyse_multipair(state)\n",
    "    display(format_multipair_summary(multipair_summary))\n",
    "else:\n",
    "    print(\"This strategy traded only a single trading pair or no trades\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
